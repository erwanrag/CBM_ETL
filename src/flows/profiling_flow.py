"""
Profiling intelligent des colonnes ETL
- Analyse TOUTES les donn√©es en staging (pas d'√©chantillon)
- V√©rification date dernier profiling
- Force possible
- Int√©gration optionnelle dans load_flow
"""
import sys
import os
from pathlib import Path
from datetime import datetime, timedelta

sys.path.insert(0, str(Path(__file__).parent.parent.parent))

from dotenv import load_dotenv
load_dotenv(Path(__file__).parent.parent.parent / ".env")

import pandas as pd
import pyodbc
from prefect import flow, task
from src.utils.connections import get_sqlserver_connection
from src.etl_logger import ETLLogger

SQLSERVER_CONN = (
    "DRIVER={ODBC Driver 17 for SQL Server};"
    f"SERVER={os.getenv('SQL_SERVER')};"
    f"DATABASE={os.getenv('SQL_DATABASE')};"
    "Trusted_Connection=yes;"
    "Connection Timeout=300;"
    "Command Timeout=600;"
)


@task
def check_profiling_needed(table_name: str, force: bool = False, days_threshold: int = 14):
    """
    V√©rifie si profiling n√©cessaire
    
    Args:
        table_name: Nom de la table
        force: Si True, profiling m√™me si r√©cent
        days_threshold: Nombre de jours avant re-profiling
    
    Returns:
        tuple: (bool: profiling_needed, datetime: last_profiling_ts)
    """
    conn = get_sqlserver_connection()
    
    # R√©cup√©rer date dernier profiling
    df = pd.read_sql("""
        SELECT LastProfilingTs
        FROM config.ETL_Tables
        WHERE TableName = ?
    """, conn, params=[table_name])
    
    conn.close()
    
    if df.empty:
        raise ValueError(f"Table {table_name} introuvable dans ETL_Tables")
    
    last_profiling = df.iloc[0]['LastProfilingTs']
    
    # Force : toujours faire profiling
    if force:
        print(f"üîÑ Profiling FORC√â pour {table_name}")
        return True, last_profiling
    
    # Jamais profil√© : profiling n√©cessaire
    if pd.isna(last_profiling):
        print(f"‚ÑπÔ∏è  {table_name} : Jamais profil√© ‚Üí Profiling n√©cessaire")
        return True, None
    
    # V√©rifier anciennet√©
    days_since = (datetime.now() - last_profiling).days
    
    if days_since >= days_threshold:
        print(f"‚ö†Ô∏è  {table_name} : Dernier profiling il y a {days_since}j (seuil: {days_threshold}j) ‚Üí Profiling n√©cessaire")
        return True, last_profiling
    else:
        print(f"‚úÖ {table_name} : Profiling r√©cent ({days_since}j) ‚Üí Skip")
        return False, last_profiling


@task
def profile_staging_table(table_name: str, min_empty_pct: float = 90.0, min_distinct_ratio: float = 0.01):
    """
    Profile TOUTES les donn√©es en staging (pas d'√©chantillon)
    
    Args:
        table_name: Nom de la table
        min_empty_pct: Seuil % vide pour exclusion (d√©faut 90%)
        min_distinct_ratio: Ratio minimum distinct/total pour colonnes non-statiques (1% par d√©faut)
    
    Returns:
        pd.DataFrame: R√©sultat profiling avec recommandations
    """
    conn = get_sqlserver_connection()
    cursor = conn.cursor()
    
    print(f"\n{'='*80}")
    print(f"üìä PROFILING : stg.{table_name}")
    print(f"{'='*80}")
    
    # 1. Compter lignes totales
    cursor.execute(f"SELECT COUNT(*) FROM stg.{table_name}")
    total_rows = cursor.fetchone()[0]
    
    if total_rows == 0:
        print(f"‚ö†Ô∏è  Table stg.{table_name} vide ‚Üí Profiling impossible")
        conn.close()
        return pd.DataFrame()
    
    print(f"üìà Total lignes : {total_rows:,}")
    
    # 2. R√©cup√©rer structure colonnes
    cursor.execute(f"""
        SELECT COLUMN_NAME, DATA_TYPE
        FROM INFORMATION_SCHEMA.COLUMNS
        WHERE TABLE_SCHEMA = 'stg' AND TABLE_NAME = ?
          AND COLUMN_NAME NOT IN ('hashdiff', 'ts_source', 'load_ts')
        ORDER BY ORDINAL_POSITION
    """, (table_name,))
    
    columns = cursor.fetchall()
    
    if not columns:
        print(f"‚ö†Ô∏è  Aucune colonne trouv√©e pour stg.{table_name}")
        conn.close()
        return pd.DataFrame()
    
    print(f"üìä Colonnes √† profiler : {len(columns)}")
    
    # 3. Profiler chaque colonne
    results = []
    
    for i, (col_name, col_type) in enumerate(columns, 1):
        print(f"\r[{i}/{len(columns)}] Profiling : {col_name:30}", end="", flush=True)
        
        try:
            # Compter NULL
            cursor.execute(f"""
                SELECT COUNT(*) 
                FROM stg.{table_name}
                WHERE [{col_name}] IS NULL
            """)
            null_count = cursor.fetchone()[0]
            
            # Compter valeurs vides (pour VARCHAR)
            empty_count = 0
            if col_type in ['varchar', 'nvarchar', 'char', 'nchar']:
                cursor.execute(f"""
                    SELECT COUNT(*) 
                    FROM stg.{table_name}
                    WHERE LTRIM(RTRIM([{col_name}])) = ''
                """)
                empty_count = cursor.fetchone()[0]
            
            # Compter valeurs distinctes
            cursor.execute(f"""
                SELECT COUNT(DISTINCT [{col_name}])
                FROM stg.{table_name}
                WHERE [{col_name}] IS NOT NULL
            """)
            distinct_count = cursor.fetchone()[0]
            
            # Calculer m√©triques
            empty_total = null_count + empty_count
            empty_pct = (empty_total / total_rows * 100) if total_rows > 0 else 0
            distinct_ratio = (distinct_count / total_rows) if total_rows > 0 else 0
            
            # D√©terminer si colonne √† exclure
            is_static = distinct_count <= 1  # ‚â§1 valeur unique
            is_fully_empty = empty_pct >= 99.9  # Quasi 100% vide
            is_mostly_empty_and_static = empty_pct >= min_empty_pct and distinct_count <= 2
            
            # R√àGLE CRITIQUE : Si >1% rempli ET valeurs vari√©es ‚Üí GARDER !
            has_meaningful_data = empty_pct < 99.0 and distinct_count > 2
            
            # Exclure SEULEMENT si :
            # 1. Statique (‚â§1 valeur) OU
            # 2. Quasi 100% vide (‚â•99.9%) OU  
            # 3. >90% vide ET ‚â§2 valeurs (ex: flag binaire rarement utilis√©)
            recommend_exclude = (is_static or is_fully_empty or is_mostly_empty_and_static) and not has_meaningful_data
            
            # Raison exclusion
            reasons = []
            if is_static:
                reasons.append("Statique (‚â§1 valeur)")
            elif is_fully_empty:
                reasons.append(f"{empty_pct:.1f}% vide")
            elif is_mostly_empty_and_static:
                reasons.append(f"{empty_pct:.1f}% vide + ‚â§2 valeurs")
            
            if has_meaningful_data and recommend_exclude:
                reasons.append("‚ö†Ô∏è CONSERV√âE (>1% donn√©es vari√©es)")
                recommend_exclude = False
            
            reason = " | ".join(reasons) if reasons else "Colonne active"
            
            results.append({
                'ColumnName': col_name,
                'DataType': col_type,
                'TotalRows': total_rows,
                'NullCount': null_count,
                'EmptyCount': empty_count,
                'EmptyTotal': empty_total,
                'EmptyPct': round(empty_pct, 2),
                'DistinctCount': distinct_count,
                'DistinctRatio': round(distinct_ratio, 4),
                'RecommendExclude': recommend_exclude,
                'Reason': reason
            })
            
        except Exception as e:
            print(f"\n‚ö†Ô∏è  Erreur profiling {col_name} : {e}")
            results.append({
                'ColumnName': col_name,
                'DataType': col_type,
                'TotalRows': total_rows,
                'NullCount': None,
                'EmptyCount': None,
                'EmptyTotal': None,
                'EmptyPct': None,
                'DistinctCount': None,
                'DistinctRatio': None,
                'RecommendExclude': False,
                'Reason': f"Erreur: {str(e)[:100]}"
            })
    
    print()  # Nouvelle ligne apr√®s progression
    
    conn.close()
    
    return pd.DataFrame(results)


@task
def save_profiling_report(table_name: str, profiling_df: pd.DataFrame):
    """Sauvegarde rapport profiling en CSV"""
    output_dir = Path(__file__).parent.parent / "profiling_reports"
    output_dir.mkdir(exist_ok=True)
    
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    report_file = output_dir / f"profiling_{table_name}_{timestamp}.csv"
    
    profiling_df.to_csv(report_file, index=False, encoding='utf-8-sig')
    
    print(f"\nüìÑ Rapport sauvegard√© : {report_file}")
    
    return str(report_file)


@task
def apply_exclusions(table_name: str, profiling_df: pd.DataFrame, auto_apply: bool = False):
    """
    Applique les exclusions recommand√©es dans config.ETL_Columns
    
    Args:
        table_name: Nom de la table
        profiling_df: DataFrame avec recommandations
        auto_apply: Si True, applique automatiquement. Sinon, demande confirmation.
    
    Returns:
        int: Nombre de colonnes exclues
    """
    to_exclude = profiling_df[profiling_df['RecommendExclude'] == True]
    
    if len(to_exclude) == 0:
        print("\n‚úÖ Aucune colonne √† exclure")
        return 0
    
    print(f"\n{'='*80}")
    print(f"üìã RECOMMANDATIONS D'EXCLUSION : {len(to_exclude)} colonne(s)")
    print(f"{'='*80}")
    
    for _, row in to_exclude.iterrows():
        print(f"‚ùå {row['ColumnName']:30} {row['Reason']}")
    
    # Confirmation si non auto
    if not auto_apply:
        print(f"\n‚ö†Ô∏è  Appliquer ces exclusions dans config.ETL_Columns ?")
        response = input("   [O]ui / [N]on : ").strip().upper()
        
        if response != 'O':
            print("‚è≠Ô∏è  Exclusions NON appliqu√©es")
            return 0
    
    # Appliquer exclusions
    conn = get_sqlserver_connection()
    cursor = conn.cursor()
    
    excluded_count = 0
    
    for _, row in to_exclude.iterrows():
        col_name = row['ColumnName']
        reason = row['Reason']
        
        cursor.execute("""
            UPDATE config.ETL_Columns
            SET IsExcluded = 1,
                Notes = ?
            WHERE TableName = ? AND ColumnName = ?
        """, (f"Auto-profiling: {reason}", table_name, col_name))
        
        excluded_count += cursor.rowcount
    
    conn.commit()
    cursor.close()
    conn.close()
    
    print(f"\n‚úÖ {excluded_count} colonne(s) exclue(s) dans config.ETL_Columns")
    
    return excluded_count


@task
def update_profiling_timestamp(table_name: str):
    """Met √† jour LastProfilingTs dans ETL_Tables"""
    conn = get_sqlserver_connection()
    cursor = conn.cursor()
    
    now = datetime.now()
    
    cursor.execute("""
        UPDATE config.ETL_Tables
        SET LastProfilingTs = ?
        WHERE TableName = ?
    """, (now, table_name))
    
    conn.commit()
    cursor.close()
    conn.close()
    
    print(f"‚úÖ LastProfilingTs mis √† jour : {now.strftime('%Y-%m-%d %H:%M:%S')}")


@flow(name="Profiling Flow V2")
def profiling_flow(
    table_name: str,
    force: bool = False,
    days_threshold: int = 14,
    auto_apply: bool = False,
    min_empty_pct: float = 90.0
):
    """
    Flow de profiling intelligent
    
    Args:
        table_name: Nom de la table √† profiler
        force: Forcer profiling m√™me si r√©cent
        days_threshold: Seuil jours avant re-profiling (14 par d√©faut)
        auto_apply: Appliquer automatiquement exclusions sans confirmation
        min_empty_pct: Seuil % vide pour exclusion (90% par d√©faut)
    
    Returns:
        dict: R√©sultat profiling
    """
    logger = ETLLogger(SQLSERVER_CONN)
    start_time = datetime.now()
    
    print(f"\n{'='*80}")
    print(f"üîç PROFILING FLOW V2 : {table_name}")
    print(f"   Force : {force}")
    print(f"   Seuil : {days_threshold} jours")
    print(f"   Auto-apply : {auto_apply}")
    print(f"{'='*80}")
    
    try:
        logger.log_step(table_name, "profiling_start", "started")
        
        # 1. V√©rifier si profiling n√©cessaire
        profiling_needed, last_profiling = check_profiling_needed(
            table_name, force, days_threshold
        )
        
        if not profiling_needed:
            print(f"\n‚úÖ Profiling non n√©cessaire pour {table_name}")
            logger.log_step(table_name, "profiling_skipped", "success")
            return {
                'status': 'skipped',
                'reason': 'Profiling r√©cent',
                'last_profiling': last_profiling
            }
        
        # 2. Profiler colonnes depuis staging
        profiling_df = profile_staging_table(table_name, min_empty_pct=min_empty_pct)
        
        if profiling_df.empty:
            print(f"‚ö†Ô∏è  Profiling impossible (table vide ou erreur)")
            logger.log_step(table_name, "profiling_failed", "failed", error="Table vide")
            return {'status': 'failed', 'reason': 'Table vide'}
        
        # 3. Sauvegarder rapport
        report_file = save_profiling_report(table_name, profiling_df)
        
        # 4. Afficher r√©sum√©
        total_cols = len(profiling_df)
        to_exclude = len(profiling_df[profiling_df['RecommendExclude'] == True])
        active = total_cols - to_exclude
        
        print(f"\n{'='*80}")
        print(f"üìä R√âSUM√â PROFILING")
        print(f"{'='*80}")
        print(f"Total colonnes    : {total_cols}")
        print(f"Colonnes actives  : {active} ({active/total_cols*100:.1f}%)")
        print(f"√Ä exclure         : {to_exclude} ({to_exclude/total_cols*100:.1f}%)")
        print(f"{'='*80}")
        
        # 5. Appliquer exclusions
        excluded_count = apply_exclusions(table_name, profiling_df, auto_apply)
        
        # 6. Mettre √† jour timestamp
        update_profiling_timestamp(table_name)
        
        # 7. Log succ√®s
        duration = (datetime.now() - start_time).total_seconds()
        logger.log_step(
            table_name, 
            "profiling_complete", 
            "success",
            duration=duration
        )
        
        print(f"\n‚úÖ Profiling termin√© ({duration:.1f}s)")
        
        return {
            'status': 'success',
            'total_columns': total_cols,
            'active_columns': active,
            'excluded_columns': excluded_count,
            'report_file': report_file,
            'duration': duration
        }
        
    except Exception as e:
        logger.log_step(table_name, "profiling_failed", "failed", error=str(e))
        print(f"\n‚ùå Erreur profiling : {e}")
        raise


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description='Profiling intelligent colonnes ETL')
    parser.add_argument('table_name', help='Nom de la table √† profiler')
    parser.add_argument('--force', action='store_true', help='Forcer profiling m√™me si r√©cent')
    parser.add_argument('--days', type=int, default=14, help='Seuil jours avant re-profiling (d√©faut: 14)')
    parser.add_argument('--auto-apply', action='store_true', help='Appliquer exclusions automatiquement')
    parser.add_argument('--min-empty-pct', type=float, default=90.0, help='Seuil %% vide pour exclusion (d√©faut: 90)')
    
    args = parser.parse_args()
    
    profiling_flow(
        table_name=args.table_name,
        force=args.force,
        days_threshold=args.days,
        auto_apply=args.auto_apply,
        min_empty_pct=args.min_empty_pct
    )